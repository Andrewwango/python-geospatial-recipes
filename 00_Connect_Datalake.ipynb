{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d50df568-1037-4db6-80e8-67af3a07b691",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Connect to datalake in Azure Storage Account\n",
    "\n",
    "Run this code to mount your Azure Storage Account to Databricks.\n",
    "\n",
    "This assumes you have a storage account `dbcopgeospatial`. Remember to remove the storage account key before committing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82e8a9ba-8b39-4973-955f-d2bf802245e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Credentials\n",
    "STORAGE_ACCOUNT_NAME = \"dbcopgeospatial\"\n",
    "STORAGE_ACCOUNT_KEY = \"\"\n",
    "\n",
    "# Paths\n",
    "PATH_EXTERNAL_BLOB = f\"wasbs://external@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/\"\n",
    "PATH_DATALAKE = f\"wasbs://copgeospatial@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/\"\n",
    "PATH_ANALYSIS = f\"wasbs://analysis@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/\"\n",
    "\n",
    "# Connect blob\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    STORAGE_ACCOUNT_KEY,\n",
    ")\n",
    "\n",
    "# Mounts\n",
    "def mount(mount_name: str, source: str, mount_root: str = \"/mnt\") -> None:\n",
    "    \"\"\"\n",
    "    Mounts source location to local path under mount_local_root. Will ignore if mount\n",
    "    alreay exits.\n",
    "\n",
    "    Note: This function expects access to global STORAGE_ACCOUNT_NAME and\n",
    "    STORAGE_ACCOUNT_KEY constants.\n",
    "\n",
    "    Parameters:\n",
    "        - local_name: mounted local directory name (subdirectory of mount_local_root)\n",
    "        - source: location of source (e.g. blob container)\n",
    "        - mount_local_root (optional): the root path of the local mounts\n",
    "    \"\"\"\n",
    "    if f\"{mount_name}/\" not in [\n",
    "        fileinfo.name for fileinfo in dbutils.fs.ls(mount_root)\n",
    "    ]:\n",
    "        print(mount_name)\n",
    "        dbutils.fs.mount(\n",
    "            source=source,\n",
    "            mount_point=os.path.join(mount_root, mount_name),\n",
    "            extra_configs={\n",
    "                f\"fs.azure.account.key.{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\": STORAGE_ACCOUNT_KEY\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "for name, container in zip(\n",
    "    [\"copgeospatial\"],\n",
    "    [PATH_DATALAKE],\n",
    "):\n",
    "    mount(name, container)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Connect_Datalake",
   "notebookOrigID": 1341489215653001,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
